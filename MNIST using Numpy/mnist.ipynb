{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1724775982341,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"dBtLNu2DnY5d"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1724775982968,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"uw_Iy86fsaQS"},"outputs":[],"source":["## Function for converting ubyte file into CSV file\n","\n","##Function name: \"Convert\"\n","\"\"\"\n","Parameters:\n","1. \"imgs\" : The path to the binary image file\n","2. \"labels\" : The path to the binary label file\n","3. \"outfile\" : The path where the CSV file will be saved\n","4. \"n\" : The number of images to process\n","\"\"\"\n","\n","def convert(imgs, labels, outfile, n):\n","  \"\"\"\n","  Opening the files.\n","  The function open the image file and label file in binary read mode(\"rb\")\n","  The function open the output CSV file in write mode(\"w\")\n","  \"\"\"\n","  imagefile = open(imgs, \"rb\")\n","  labelfile = open(labels, \"rb\")\n","  csvfile = open(outfile, \"w\")\n","\n","  \"\"\"\n","  Skipping Headers.\n","  The function reads and discards the first 16  bytes of the image file and the first 8 bytes of the label file. These bytes typically contain metadata about the files, such as magic numbers and dimensions, which are not needed for the conversion.\n","  \"\"\"\n","  imagefile.read(16)\n","  labelfile.read(8)\n","\n","  \"\"\"An empty list named \"images\" is initailized to store the processed image data.\"\"\"\n","  images = []\n","\n","  \"\"\"\n","  Reading images and Labels.\n","  The outer loop iterates \"n\" times, where \"n\" is the number of images to read.\n","  For each iteration:\n","    It reads one byte from the label file, which represents the label of the image(converted to an integer using \"ord()\").\n","    It then reads 784 bytes(28*28 pixels) from the image file, appending them to the \"image\" list. Each pixel value is also converted to an integer using \"ord()\".\n","    It then stores the processed image in the \"images\" list\n","  \"\"\"\n","  for i in range(n):\n","    image = [ord(labelfile.read(1))]\n","    for j in range(28*28):\n","      image.append(ord(imagefile.read(1)))\n","    images.append(image)\n","\n","  \"\"\"\n","  Writing to CSV\n","  This loop iterates over the \"images\" list and writes each image's pixel values and label to the CSV file.\n","  The pixel values are joined into a single string separated by commas, and a newline character is added at the end of each line.\n","  \"\"\"\n","  for image in images:\n","    csvfile.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n","\n","  \"\"\"\n","  Finally, the function closes all opened files to free up the system resources.\n","  \"\"\"\n","  imagefile.close()\n","  labelfile.close()\n","  csvfile.close()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1724775984211,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"TL0EUPpwrt-i"},"outputs":[],"source":["# Defining the training and the test set of the MNIST Dataset\n","mnist_train_x = \"MNIST_Dataset/train-images.idx3-ubyte\"\n","mnist_train_y = \"MNIST_Dataset/train-labels.idx1-ubyte\"\n","\n","mnist_test_x = \"MNIST_Dataset/t10k-images.idx3-ubyte\"\n","mnist_test_y = \"MNIST_Dataset/t10k-labels.idx1-ubyte\""]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":24655,"status":"ok","timestamp":1724776009261,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"px31IPH7r3p9"},"outputs":[],"source":["convert(mnist_train_x, mnist_train_y, \"mnist_train.csv\", 60000)\n","convert(mnist_test_x, mnist_train_y, \"mnist_test.csv\", 10000)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":622,"status":"ok","timestamp":1724776011680,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"-e4qzZX3z9Ry"},"outputs":[],"source":["#Opening and reading the training file.\n","\n","\"\"\"\n","The line opens the file named \"mnist_train.csv\" in read mode (\"r\"). This file is expected to contain training data for the MNIST dataset.\n","\"\"\"\n","train_file = open(\"mnist_train.csv\", \"r\")\n","\n","\"\"\"\n","The line reads all the lines from the file and stores them in a list called \"train_list\". Each element in this list corresponds to a line in the CSV file, which typically contains pixel values and labels for each image.\n","\"\"\"\n","train_list = train_file.readlines()\n","\n","\"\"\"\n","The line closes the file to ensure that system resources are released. It is important to close files after you are done with them to prevent memory leaks or file corruption.\n","\"\"\"\n","train_file.close()\n","\n","\n","# Opening and reading the test file.\n","\n","\"\"\"\n","The line opens the file named \"mnist_test.csv\" in read mode (\"r\"). This file is expected to contain test data for the MNIST dataset.\n","\"\"\"\n","test_file = open(\"mnist_test.csv\", \"r\")\n","\n","\"\"\"\n","The line reads all the lines from the file and stores them in a list called \"test_list\". Each element in this list corresponds to a line in the CSV file, which typically contains pixel values and labels for each image.\n","\"\"\"\n","test_list = test_file.readlines()\n","\n","\"\"\"\n","The line closes the file to ensure that system resources are released. It is important to close files after you are done with them to prevent memory leaks or file corruption.1\n","\"\"\"\n","test_file.close()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724776012922,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"tuC663LU0NwB","outputId":"5fa00f21-9474-4903-9102-ea91ef5360ba"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,18,46,136,136,244,255,241,103,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,94,163,253,253,253,253,238,218,204,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,131,253,253,253,253,237,200,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,155,246,253,247,108,65,45,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,207,253,253,230,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,157,253,253,125,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,250,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,247,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,247,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,247,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,231,249,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,225,253,231,213,213,123,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,172,253,253,253,253,253,190,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,116,72,124,209,253,253,141,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,219,253,206,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,104,246,253,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,213,253,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,226,253,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,132,253,209,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,78,253,86,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_list[100]"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1724776015929,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"yvRBTkq50l23","outputId":"9b21c5a9-02de-4b44-9a80-76273166c0d8"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7c2df8480cd0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\"\"\"\n","Selecting a Training Example.\n","  This line selects the 100th element(index 100) from the \"train_list\" list, which represents a single training example from the MNIST dataset.\n","  The \"split(\",\")\" method splits the selected line(a string) into a list of values, using commas as the delimiter. This effectively separates the label and pixel values.\n","  The resulting list is then assigned to the variable \"values\".\n","\"\"\"\n","values = train_list[100].split(\",\")\n","\n","\"\"\"\n","Extracting Pixel Values.\n","  \"values[1:]\" selects all the elements from index 1 onwards, effectively skipping the first element which the label.\n","  \"np.asfarray()\" converts the selected values to a NumPy array of floating-point numbers.\n","  \"reshape((28, 28))\" reshapes the 1D array of pixel values into a 2D array of size 28x28, which corresponds to the dimension of an MNIST image.\n","\"\"\"\n","image_array = np.asfarray(values[1:]).reshape((28, 28))\n","\n","\"\"\"\n","Displaying the Image.\n","  This line uses the \"imshow()\" function from the Matplotlib library to display the image represented by \"image_array\".\n","  \"cmap = \"Greys\" sets the colormap to grayscale, which is suitable for displaying MNIST images.\n","  \"interpolation = \"None\"\" disbales any interpolation, which ensures that the pixels are displayed as-is without any smoothing.\n","\"\"\"\n","plt.imshow(image_array, cmap = \"Greys\", interpolation = \"None\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":448,"status":"ok","timestamp":1724776019010,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"tSGO-QKT2A8z"},"outputs":[],"source":["class DNN:\n","  \"\"\"\n","  Parameters:\n","    \"sizes\" : A list defining the number of inputs in each layer. The default is \"[784, 196, 49, 10]\", indicating an iput layer with 784 neurons, two hidden layers with 196 and 49 neurons respectively, and an output layer with 10 neurons(for classifying 10 digits).\n","    \"epochs\" : The number of training iterations(default is 10).\n","    \"lr\" : Learning rate for weight updates(default is 0.001)\n","  \"\"\"\n","  def __init__(self, sizes = [784, 196, 49, 10], epochs = 10, lr = 0.001):\n","    self.sizes = sizes\n","    self.epochs = epochs\n","    self.lr = lr\n","\n","    input_layer = sizes[0]\n","    hidden_1 = sizes[1]\n","    hidden_2 = sizes[2]\n","    output_layer = sizes[3]\n","\n","    \"\"\"\n","    Weight Initialization:\n","      The weights for each layer are initialized using a normal distribution scaled by the square root of the number of neurons in the layer. This helps in preventing issues like vanishing or exploding gradients during training.\n","    \"\"\"\n","\n","    self.params = {\n","        \"W1\" : np.random.randn(hidden_1, input_layer) * np.sqrt(1./hidden_1),      # 196x784\n","        \"W2\" : np.random.randn(hidden_2, hidden_1) * np.sqrt(1./hidden_2),         # 49x196\n","        \"W3\" : np.random.randn(output_layer, hidden_2) * np.sqrt(1./output_layer)  # 10x49\n","    }\n","\n","\n","    #Activation Function:\n","\n","  \"\"\"\n","  Sigmoid: Used as an activation function for hidden layers. It squashes inputs to a range between 0 and 1.\n","  \"\"\"\n","  def sigmoid(self, x, derivative = False):\n","    if derivative:\n","      return (np.exp(-x)) / (np.exp(-x) + 1)**2\n","    return 1 / (1 + np.exp(-x))\n","\n","  \"\"\"\n","  Tanh: Another activation function that outputs values between -1 and 1. Although defined, it is not used in the forward pass in this implementation.\n","  \"\"\"\n","  def tanH(self, x, derivative = False):\n","    if derivative:\n","      return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n","    return np.tanh(x)\n","\n","  \"\"\"\n","  Softmax: Used in the output layer to convert logits into probabilites. It ensures the output sums to 1, making it suitable for multi-class classification.\n","  \"\"\"\n","  def softmax(self, x, derivative = False):\n","    exps = np.exp(x - x.max())\n","    if derivative:\n","      return exps / np.sum(exps, axis = 0) * (1 - exps/np.sum(exps, axis = 0))\n","    return exps / np.sum(exps, axis = 0)\n","\n","  # Forward Pass: \"forward_pass\"\n","  \"\"\"\n","  This method computes the output of the network given an input \"x_train\".\n","  It performs the following steps:\n","    Computes the weighted sum (linear transformation) for each layer (\"Z1\", \"Z2\", \"Z3\").\n","    Applies the activation functions to these sums to obtain the activations for each layer (\"A1\", \"A2\", \"A3\").\n","  The final output is the softmax probabilites for the classes.\n","  \"\"\"\n","\n","  def forward_pass(self, x_train):\n","    params = self.params\n","\n","    params[\"A0\"] = x_train\n","\n","    # Input Layer to Hidden_1\n","    params[\"Z1\"] = np.dot(params[\"W1\"], params[\"A0\"])\n","    params[\"A1\"] = self.sigmoid(params[\"Z1\"])\n","\n","    # Hidden_1 to Hidden_2\n","    params[\"Z2\"] = np.dot(params[\"W2\"], params[\"A1\"])\n","    params[\"A2\"] = self.sigmoid(params[\"Z2\"])\n","\n","    # Hidden_2 to Output Layer\n","    params[\"Z3\"] = np.dot(params[\"W3\"], params[\"A2\"])\n","    params[\"A3\"] = self.softmax(params[\"Z3\"])\n","\n","    return params[\"A3\"]\n","\n","  # Backward Pass:\"backward_pass\"\n","  \"\"\"\n","  This method computes the gradients for updating the weights based on the error of the output.\n","  It calculates the error for the output layer and propagates it backward through the network:\n","    Computes the gradient for \"W3\" (output layer weights) using the derivative of the softmax function.\n","    Computes the gradient for \"W2\" and \"W1\" using the chain rule, applying the derivatives of the sigmoid activation function.\n","  \"\"\"\n","  def backward_pass(self, y_train, output):\n","    params = self.params\n","\n","    change_w = {}\n","\n","    # Calculate W3 Update\n","    error = 2 * (output - y_train) / output.shape[0] * self.softmax(params[\"Z3\"], derivative = True)\n","    change_w[\"W3\"] = np.outer(error, params[\"A2\"])\n","\n","    # Calculate W2 Update\n","    error1 = np.dot(params[\"W3\"].T, error) * self.sigmoid(params[\"Z2\"], derivative = True)\n","    change_w[\"W2\"] = np.outer(error1, params[\"A1\"])\n","\n","    # Calculate W1 Update\n","    error2 =  np.dot(params[\"W2\"].T, error1) * self.sigmoid(params[\"Z1\"], derivative = True)\n","    change_w[\"W1\"] = np.outer(error2, params[\"A0\"])\n","\n","    return change_w\n","\n","  # Weight Update: \"update_weights\"\n","  \"\"\"\n","  This method updates the weights of the network using the computed gradients from the backward pass, scaled by the learning rate.\n","  \"\"\"\n","  def update_weights(self, change_w):\n","    for key, val in change_w.items():\n","      self.params[key] -= self.lr * val\n","\n","  # Accuracy Computation: \"compute_accuracy\"\n","  \"\"\"\n","  This method evaluates the model's performance on test data.\n","  It processes each test sample, normalizes the input, and computes the network's output.\n","  It compares the predicted class(using \"np.argamax\" on the output probabilites) with the true class to compute accuracy.\n","  \"\"\"\n","  def compute_accuracy(self, test_data):\n","    predictions = []\n","    for x in train_list:\n","      values = x.split(\",\")\n","      inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n","      targets = np.zeros(10) + 0.001\n","      targets[int(values[0])] = 0.99\n","      output = self.forward_pass(inputs)\n","      pred = np.argmax(output)\n","      predictions.append(pred == np.argmax(targets))\n","\n","    return np.mean(predictions)\n","\n","  # Training Method: \"train\"\n","  \"\"\"\n","  This method orchestrates the training process:\n","    Loops through the specified number of epochs.\n","    For each training sample, it performs the forward and backward passes and updates the weights.\n","    After each epoch, it computes and prints the accuracy on the test data.\n","    After each epoch, it computes and prints the accuracy on the test set.\n","  \"\"\"\n","\n","  def train(self, train_list, test_list):\n","    \"\"\"\n","    Epoch Loop: The outer loop iterates over the number of epochs during initialization(\"Self.epochs\"). Each epoch represents one complete pass through the training data.\n","    \"\"\"\n","    for i in range(self.epochs):\n","      \"\"\"\n","      Time Tracking: \"start_time = time.time()\" records the start time of the poch to measure how long it takes to complete.\n","      \"\"\"\n","      start_time = time.time()\n","      \"\"\"\n","      Training Sample Loop: The inner loop iterates over each training sample in \"train_list\".\n","      \"\"\"\n","      for x in train_list:\n","        # Data Preparation\n","        \"\"\"\n","        Splitting Input:\n","          \"values = x.split(\",\") splits the string representation of the sample into a list of strings.\n","          The first element (\"values\") is the label (the true class), and the remaining elements are pixel values.\n","        \"\"\"\n","        values = x.split(\",\")\n","        \"\"\"\n","        Normalization:\n","          \"inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01)\" converts the pixel values to a numpy array, normalizes them to a range between 0.01 and 1.0. This is done to ensure that the input values are not too small or too large, which can help with training stability.\n","        \"\"\"\n","        inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n","        \"\"\"\n","        Target Vector:\n","          \"targets = np.zeros(10) + 0.001\" initializes a target vector of size 10(for 10 classes), setting all values to 0.001. This small value helps prevent issues with zero probabilites during training.\n","          \"targets[int(values[0])] = 0.99\" sets the target value for the true class to 0.99, indicating the expected output for this sample.\n","        \"\"\"\n","        targets = np.zeros(10) + 0.001\n","        targets[int(values[0])] = 0.99\n","\n","        \"\"\"\n","        Forward Pass:\n","          \"output = self.forward_pass(inputs)\" calls the \"forward_pass\" method with the normalized inputs to compute the network's output probabilites for the classes.\n","        \"\"\"\n","        output = self.forward_pass(inputs)\n","\n","        \"\"\"\n","        Backward Pass:\n","          \"change_w = self.backward_pass(targets, output)\" calls the \"backward_pass\" method, passing the true targets and the predicted output. This method calculates the gradients of the weights based on the error between the predicted output and the true targets.\n","        \"\"\"\n","        change_w = self.backward_pass(targets, output)\n","\n","        \"\"\"\n","        Weight Update:\n","          \"self.update_weights(change_w)\" updates the weights of the network using the computed gradients form the backward pass.\n","        \"\"\"\n","        self.update_weights(change_w)\n","\n","      accuracy = self.compute_accuracy(test_list)\n","      print(f\"Epochs: {i+1}, Time Spent: {(time.time() - start_time):.2f}, Accuracy: {accuracy*100 : .2f}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1724776021162,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"UQjGXtakC9PX"},"outputs":[],"source":["dnn = DNN(sizes = [784, 196, 49, 10], epochs = 30, lr = 0.001)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2610325,"status":"ok","timestamp":1724779925325,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"},"user_tz":-330},"id":"onCeAybaC-2x","outputId":"bb28a3f4-6dc8-460c-9e73-d4e7835b5088"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epochs: 1, Time Spent: 132.49, Accuracy:  21.38\n","Epochs: 2, Time Spent: 130.98, Accuracy:  33.14\n","Epochs: 3, Time Spent: 128.66, Accuracy:  33.92\n","Epochs: 4, Time Spent: 128.55, Accuracy:  34.88\n","Epochs: 5, Time Spent: 129.10, Accuracy:  38.71\n","Epochs: 6, Time Spent: 129.31, Accuracy:  43.02\n","Epochs: 7, Time Spent: 130.53, Accuracy:  46.55\n","Epochs: 8, Time Spent: 133.35, Accuracy:  49.91\n","Epochs: 9, Time Spent: 129.48, Accuracy:  52.97\n","Epochs: 10, Time Spent: 130.67, Accuracy:  55.81\n","Epochs: 11, Time Spent: 129.02, Accuracy:  58.24\n","Epochs: 12, Time Spent: 130.19, Accuracy:  60.17\n","Epochs: 13, Time Spent: 130.96, Accuracy:  61.76\n","Epochs: 14, Time Spent: 130.15, Accuracy:  62.99\n","Epochs: 15, Time Spent: 127.64, Accuracy:  64.22\n","Epochs: 16, Time Spent: 130.63, Accuracy:  65.29\n","Epochs: 17, Time Spent: 129.11, Accuracy:  66.20\n","Epochs: 18, Time Spent: 127.66, Accuracy:  67.03\n","Epochs: 19, Time Spent: 128.24, Accuracy:  67.81\n","Epochs: 20, Time Spent: 136.17, Accuracy:  68.48\n","Epochs: 21, Time Spent: 132.21, Accuracy:  69.16\n","Epochs: 22, Time Spent: 131.00, Accuracy:  69.79\n","Epochs: 23, Time Spent: 129.18, Accuracy:  70.46\n","Epochs: 24, Time Spent: 127.94, Accuracy:  71.12\n","Epochs: 25, Time Spent: 129.40, Accuracy:  71.80\n","Epochs: 26, Time Spent: 128.60, Accuracy:  72.41\n","Epochs: 27, Time Spent: 128.96, Accuracy:  73.12\n","Epochs: 28, Time Spent: 131.13, Accuracy:  73.82\n","Epochs: 29, Time Spent: 128.93, Accuracy:  74.49\n","Epochs: 30, Time Spent: 130.85, Accuracy:  75.19\n"]}],"source":["dnn.train(train_list, test_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xibFV7SuUjyG"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMwyEB1MI8cMwtirELNLeQ6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
